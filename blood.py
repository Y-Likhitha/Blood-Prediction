# -*- coding: utf-8 -*-
"""Blood.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13agOkDyueWuGVYVXdLj31kuFB3qASM9Q
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt


# Commented out IPython magic to ensure Python compatibility.

df=pd.read_excel('/content/BLD-1.xlsx')
df1=pd.read_csv('/content/BLD-2.csv')
df=pd.concat([df,df1],ignore_index=True)

df.columns

df.shape

df.size

df.dtypes

df.describe()

df.head(2)

df.drop('Unnamed: 0',axis=1,inplace=True)

df.head(2)

sns.scatterplot(x=df['Months since Last Donation'],y=df['Number of Donations'],hue=df['Made Donation in March 2007'])

can,fig=plt.subplots(3,2,figsize=(8,8))
fig=fig.flatten()
j=0
for i in (df.columns):
  sns.histplot(df.loc[:,i],kde=True,ax=fig[j])
  j+=1

len(df.select_dtypes(include="number").columns)

can,fig=plt.subplots(3,2,figsize=(8,8))
fig=fig.flatten()
j=0
for i in (df.select_dtypes(include="number").columns):
  sns.boxplot(df.loc[:,i],ax=fig[j])
  j+=1

df.select_dtypes(include="number").columns

outcol=['Number of Donations','Total Volume Donated (c.c.)']
for col in outcol:
  q1=df[col].quantile(0.25)
  q3=df[col].quantile(0.75)
  iqr=q3-q1
  ll=q1-1.5*iqr
  ul=q3+1.5*iqr
  df=df[(df[col]>ll)&(df[col]<ul)]

ip=df.drop('Made Donation in March 2007',axis=1)
op=df['Made Donation in March 2007']

op.value_counts()

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(ip,op,random_state=42)

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train=sc.fit_transform(x_train)
x_test=sc.transform(x_test)

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import BernoulliNB
from sklearn.metrics import accuracy_score
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier

models=[LogisticRegression(),SVC(),BernoulliNB()]
for i in models:
  model=i
  model.fit(x_train,y_train)
  pred=model.predict(x_test)
  print(i,'= ',accuracy_score(y_test,pred)) # svc will give more acc becoz data is non-linear

model=RandomForestClassifier()
model.fit(x_train,y_train)
pred=model.predict(x_test)
print(accuracy_score(y_test,pred))

from sklearn.model_selection import cross_val_score
score=cross_val_score(RandomForestClassifier(),x_train,y_train)
print(score.mean(),score.std())

from sklearn.model_selection import GridSearchCV
params = {
     'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
}
grid=GridSearchCV(RandomForestClassifier(),params,verbose=1,cv=2)
grid.fit(x_train,y_train)
grid.best_estimator_

model=RandomForestClassifier(max_depth=20)
model.fit(x_train,y_train)
pred=model.predict(x_test)
print(accuracy_score(y_test,pred))


